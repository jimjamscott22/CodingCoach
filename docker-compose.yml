version: '3.8'

services:
  coding-coach:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: coding-coach-app
    ports:
      - "3000:3000"
    environment:
      # AI Provider configuration
      - AI_PROVIDER=${AI_PROVIDER:-ollama}
      
      # Ollama configuration
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1:8b-instruct}
      
      # LM Studio configuration (alternative)
      # - LMSTUDIO_BASE_URL=${LMSTUDIO_BASE_URL:-http://host.docker.internal:1234}
      # - LMSTUDIO_MODEL=${LMSTUDIO_MODEL:-your-model-id}
      
      # Optional model override
      # - AI_MODEL=${AI_MODEL}
    restart: unless-stopped
    networks:
      - coding-coach-network
    # Uncomment below to mount .env file directly
    # env_file:
    #   - .env.local

networks:
  coding-coach-network:
    driver: bridge
